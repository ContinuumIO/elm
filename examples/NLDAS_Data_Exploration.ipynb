{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLDAS Data Exploration\n",
    "\n",
    "This notebook accomplishes the following:\n",
    "\n",
    "- Downloads data file(s) from NASA\n",
    "- Show attribute statistics and visualizations\n",
    "- Do viz-related data cleaning\n",
    "- Show (corrected) attribute statistics and visualizations\n",
    "\n",
    "### Setup Instructions:\n",
    "1. Create *.netrc* file in home dir according to [GES DISC site instructions](https://disc.gsfc.nasa.gov/information/howto?title=How%20to%20Download%20Data%20Files%20from%20HTTP%20Service%20with%20wget)\n",
    "2. Create environment, install notebook pkgs, enable extension:\n",
    "```\n",
    "conda env create -n elm python=2.7 # 2.7 needed for pynio\n",
    "source activate elm\n",
    "conda install -c conda-forge pycurl lxml holoviews\n",
    "jupyter nbextension enable --py widgetsnbextension # This should report \"OK\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "import six\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from example_utils import GRBSelector, get_metadata, dl_file\n",
    "\n",
    "hv.notebook_extension('bokeh')\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download NLDAS GRIB file\n",
    "\n",
    "This persists the file to disk, then loads the data into RAM as an xarray Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GRBSelector()\n",
    "selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.selected_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = dl_file(selector.selected_url)\n",
    "ds = xr.open_dataset(data_fpath, engine='pynio')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes alongside their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = []\n",
    "for k in ds.data_vars:\n",
    "    raster = ds[k]\n",
    "    about = (k, raster.long_name, raster.units, raster.initial_time)\n",
    "    about_raster = '{:<20} {} ({}) - {}'.format(*about)\n",
    "    info.append(about_raster)\n",
    "print('Rasters in {}\\n'.format(os.path.basename(data_fpath)), '\\n  '.join(info), sep='\\n  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics and visualizations\n",
    "\n",
    "Below we show the data as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_dataframe().describe(percentiles=(0.025, 0.05, 0.25, 0.5, 0.75, 0.95, 0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%opts Image RGB [width=300 height=200]\n",
    "hvds = hv.Dataset(ds)\n",
    "imgs = [hvds.to(hv.Image, ['lon_110', 'lat_110'], var).relabel(var) for var in ds.data_vars]\n",
    "hv.Layout(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz-related data cleaning\n",
    "\n",
    "Noticing that -9999 seems to confuse the visualizations, we replace -9999 values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_to_na(da):\n",
    "    da.values[np.isclose(da.values, -9999.)] = 0\n",
    "ds.apply(set_to_na)\n",
    "ds.to_dataframe().describe(percentiles=(0.025, 0.05, 0.25, 0.5, 0.75, 0.95, 0.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrected visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvds = hv.Dataset(ds)\n",
    "imgs = [hvds.to(hv.Image, ['lon_110', 'lat_110'], var, group='('+ds[var].long_name+')').relabel(var) for var in ds.data_vars]\n",
    "hv.Layout(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elm.model_selection import EaSearchCV\n",
    "from xarray_filters import MLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = MLDataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "from xarray_filters.pipeline import Step\n",
    "from elm.pipeline import Pipeline\n",
    "from elm.pipeline.steps import linear_model, decomposition, cluster\n",
    "from elm.model_selection import EaSearchCV\n",
    "from elm.model_selection.sorting import pareto_front\n",
    "from elm.pipeline import Pipeline\n",
    "from elm.model_selection import CVCacheSampler\n",
    "from elm.pipeline.predict_many import predict_many\n",
    "from elm.pipeline.steps import linear_model, cluster, decomposition\n",
    "import sklearn.model_selection as sk_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = datetime.datetime(2000, 1, 1, 0, 0, 0)\n",
    "MAX_TIME_STEPS = 8\n",
    "DATES = np.array([START_DATE - datetime.timedelta(hours=hr)\n",
    "                 for hr in range(MAX_TIME_STEPS)])\n",
    "DATE_GROUPS = np.linspace(0, 5, DATES.size).astype(np.int32)\n",
    "CV_CLASSES = {'KFold': KFold}\n",
    "model_selection = {\n",
    "    'select_method': 'selNSGA2',\n",
    "    'crossover_method': 'cxTwoPoint',\n",
    "    'mutate_method': 'mutUniformInt',\n",
    "    'init_pop': 'random',\n",
    "    'indpb': 0.5,\n",
    "    'mutpb': 0.9,\n",
    "    'cxpb':  0.3,\n",
    "    'eta':   20,\n",
    "    'ngen':  2,\n",
    "    'mu':    16,\n",
    "    'k':     8, # TODO ensure that k is not ignored - make elm issue if it is\n",
    "    'early_stop': None,\n",
    "}\n",
    "\n",
    "\n",
    "class Sampler(Step):\n",
    "    def transform(self, X, y=None, **kw):\n",
    "        return dset.to_features()\n",
    "\n",
    "\n",
    "class GetY(Step):\n",
    "    layer = 'y'\n",
    "    def transform(self, X, y=None, **kw):\n",
    "        layer = self.get_params()['layer']\n",
    "        y = getattr(X, layer).values.ravel()\n",
    "        X = MLDataset(OrderedDict([(k, v) for k, v in X.data_vars.items()\n",
    "                                    if k != layer])).to_features()\n",
    "        return X.features.values, y\n",
    "    fit_transform = transform\n",
    "\n",
    "\n",
    "# TODO - also test regressors\n",
    "regress_distributions = {\n",
    "    'estimator__fit_intercept': [True, False],\n",
    "    'estimator__normalize': [True, False],\n",
    "}\n",
    "\n",
    "kmeans_distributions = {\n",
    "    'estimator__n_clusters': list(range(4, 12)),\n",
    "    'estimator__init': ['k-means++', 'random'],\n",
    "    'estimator__copy_x': [False],\n",
    "    'estimator__algorithm': [\"auto\", \"full\", \"auto\"],\n",
    "}\n",
    "pca_distributions = {\n",
    "    'pca__n_components': list(range(2, 4)),\n",
    "    'pca__whiten': [True, False],\n",
    "}\n",
    "\n",
    "regress = Pipeline([\n",
    "    ('get_y', GetY()),\n",
    "    ('estimator', linear_model.Ridge()),\n",
    "])\n",
    "\n",
    "pca_regress = Pipeline([\n",
    "    ('get_y', GetY()),\n",
    "    ('pca', decomposition.PCA()),\n",
    "    ('estimator', linear_model.Ridge()),\n",
    "])\n",
    "\n",
    "kmeans = Pipeline([\n",
    "    ('estimator', cluster.KMeans()),\n",
    "])\n",
    "\n",
    "pipes = {'one_step_unsupervised': kmeans,\n",
    "         'get_y_supervised':  regress,\n",
    "         'get_y_pca_then_regress': pca_regress,}\n",
    "\n",
    "dists = {'one_step_unsupervised': kmeans_distributions,\n",
    "         'get_y_supervised': regress_distributions,\n",
    "         'get_y_pca_then_regress': pca_distributions,}\n",
    "dists['get_y_pca_then_regress'].update(regress_distributions)\n",
    "\n",
    "DEFAULT = 'one_step_unsupervised'\n",
    "\n",
    "pipe = pipes[DEFAULT]\n",
    "param_distributions = dists[DEFAULT]\n",
    "cv = KFold()\n",
    "sampler = Sampler()\n",
    "refit_Xy = sampler.fit_transform([datetime.datetime(2000, 1, 1)])\n",
    "refit = True\n",
    "eas = []\n",
    "ea = EaSearchCV(pipe,\n",
    "                param_distributions=param_distributions,\n",
    "                sampler=sampler,\n",
    "                ngen=2,\n",
    "                model_selection=model_selection,\n",
    "                cv=cv,\n",
    "                refit=refit,\n",
    "                refit_Xy=refit_Xy)\n",
    "ea.fit(DATES) # TODO test that y is passed as a cv grouping variable\n",
    "results = getattr(ea, 'cv_results_', None)\n",
    "assert isinstance(results, dict) and 'gen' in results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
